{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Tests\n",
    "\n",
    "The next step for creating a DataCamp project in Python is creating a few tests using the `nose` testing framework, which is how DataCamp instructors deliver feedback on the code students write in a project.\n",
    "\n",
    "After installing the necessary libraries (described below), please create tests for the project tasks below, which were taken from real live DataCamp projects!\n",
    "\n",
    "When complete, please email the link to your forked repo to projects@datacamp.com with the email subject line _DataCamp project tests_. If you have any questions, please reach out to projects@datacamp.com."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To be able to run tests locally in the notebook, install the following:\n",
    "# pip install nose\n",
    "# pip install git+https://github.com/datacamp/ipython_nose\n",
    "\n",
    "# Then load in the ipython_nose extension like this:\n",
    "%load_ext ipython_nose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An example of a `nose` test\n",
    "\n",
    "Instructions to the student in the project:\n",
    "- Create a list of six to ten strings named `words` that contain words related to selling discount furniture online.\n",
    "\n",
    "A potential **incorrect** submission is as follows. Please process the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = ['buy', 'price', 'discount']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect the `nose` test below that tests the length of the list, then run the test locally. Processing the cell above followed by the cell below will run the test locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": "{\"success\": false, \"summary\": {\"tests\": 1, \"failures\": 1, \"errors\": 0}, \"tests\": [{\"name\": \"__main__.test_task_1\", \"success\": false, \"message\": \"AssertionError: There should be six to ten brief-related words in the list `words`.\\n\"}]}"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0/1 tests passed; 1 failed\n",
       "========\n",
       "__main__.test_task_1\n",
       "========\n",
       "Traceback (most recent call last):\n",
       "  File \"C:\\Users\\ASUS\\Anaconda3\\lib\\unittest\\case.py\", line 59, in testPartExecutor\n",
       "    yield\n",
       "  File \"C:\\Users\\ASUS\\Anaconda3\\lib\\unittest\\case.py\", line 615, in run\n",
       "    testMethod()\n",
       "  File \"C:\\Users\\ASUS\\Anaconda3\\lib\\site-packages\\nose\\case.py\", line 197, in runTest\n",
       "    self.test(*self.arg)\n",
       "  File \"<string>\", line 3, in test_task_1\n",
       "AssertionError: There should be six to ten brief-related words in the list `words`.\n",
       "\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%nose # needed at the start of every tests cell\n",
    "def test_task_1():\n",
    "    assert 6 <= len(set(words)) <= 10, \\\n",
    "    \"There should be six to ten brief-related words in the list `words`.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A potential **correct** submission is as follows. Please process the cell below to overwrite the correct `words` solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = ['buy', 'price', 'discount', 'promotion', 'promo', 'shop']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": "{\"success\": true, \"summary\": {\"tests\": 1, \"failures\": 0, \"errors\": 0}, \"tests\": [{\"name\": \"__main__.test_task_1\", \"success\": true, \"message\": \"\"}]}"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1/1 tests passed\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%nose # needed at the start of every tests cell\n",
    "def test_task_1():\n",
    "    assert 6 <= len(set(words)) <= 10, \\\n",
    "    \"There should be six to ten brief-related words in the list `words`.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create your first test\n",
    "Instructions to the student in the project:\n",
    "- Import the class `Image` from the library `PIL`.\n",
    "\n",
    "A potential **incorrect** submission is as follows. Please process the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-6-47ac575cf81a>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-6-47ac575cf81a>\"\u001b[1;36m, line \u001b[1;32m2\u001b[0m\n\u001b[1;33m    import Image from PIL\u001b[0m\n\u001b[1;37m                    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# import the Image class\n",
    "import Image from PIL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please fill in the `nose` test template to test if `Image` exists in `globals()` and include a helpful feedback message for failing submissions. The test should fail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": "{\"success\": false, \"summary\": {\"tests\": 1, \"failures\": 1, \"errors\": 0}, \"tests\": [{\"name\": \"__main__.test_Image_loaded\", \"success\": false, \"message\": \"AssertionError: Class 'Image' does not exist. Make sure to use the syntax: \\\"from library import class \\\" when importing a class from a library\\n\"}]}"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0/1 tests passed; 1 failed\n",
       "========\n",
       "__main__.test_Image_loaded\n",
       "========\n",
       "Traceback (most recent call last):\n",
       "  File \"C:\\Users\\ASUS\\Anaconda3\\lib\\unittest\\case.py\", line 59, in testPartExecutor\n",
       "    yield\n",
       "  File \"C:\\Users\\ASUS\\Anaconda3\\lib\\unittest\\case.py\", line 615, in run\n",
       "    testMethod()\n",
       "  File \"C:\\Users\\ASUS\\Anaconda3\\lib\\site-packages\\nose\\case.py\", line 197, in runTest\n",
       "    self.test(*self.arg)\n",
       "  File \"<string>\", line 3, in test_Image_loaded\n",
       "AssertionError: Class 'Image' does not exist. Make sure to use the syntax: \"from library import class \" when importing a class from a library\n",
       "\n"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%nose # needed at the start of every tests cell\n",
    "def test_Image_loaded():\n",
    "    assert 'Image' in globals(), \\\n",
    "    \"Class 'Image' does not exist. Make sure to use the syntax: \\\"from library import class \\\" when importing a class from a library\"  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A potential **correct** solution is as follows. Please process the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the Image class\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please copy and paste the test you just wrote into the cell below and process it. The test should pass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": "{\"success\": true, \"summary\": {\"tests\": 1, \"failures\": 0, \"errors\": 0}, \"tests\": [{\"name\": \"__main__.test_Image_loaded\", \"success\": true, \"message\": \"\"}]}"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1/1 tests passed\n"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%nose # needed at the start of every tests cell\n",
    "def test_Image_loaded():\n",
    "    assert 'Image' in globals(), \\\n",
    "    \"Class 'Image' does not exist. \\\n",
    "    Make sure to use the syntax: \\\"from library import class \\\" when importing a class from a library\"\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create your second test\n",
    "\n",
    "Instructions to the student in the project:\n",
    "- Import pandas aliased as `pd`.\n",
    "- Load `datasets/nobel.csv` into a DataFrame and assign it to the variable `nobel`.\n",
    "\n",
    "A potential **incorrect** submission is as follows. Please process the cell below. *Note: `nobel.csv` exists in a directory named `datasets` in the same directory as this `create_tests.ipynb` notebook.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'read_csv' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-e1aebb4a49a5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# read in the dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mnobel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'datasets/nobel.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'read_csv' is not defined"
     ]
    }
   ],
   "source": [
    "# load library\n",
    "import pandas\n",
    "\n",
    "# read in the dataset\n",
    "nobel = read_csv('datasets/nobel.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please fill in the two `nose` test templates below to test if `pd` exists in `globals()` and if `nobel` is correctly loaded (using the [`equals()`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.equals.html) method of a pandas DataFrame). Include a helpful feedback message for failing submissions. Both tests should fail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": "{\"success\": false, \"summary\": {\"tests\": 2, \"failures\": 2, \"errors\": 0}, \"tests\": [{\"name\": \"__main__.test_pandas_loaded\", \"success\": false, \"message\": \"AssertionError: Make sure to import pandas library with the alias pd\\n\"}, {\"name\": \"__main__.test_nobel_loaded\", \"success\": false, \"message\": \"AssertionError: The dataset 'Nobel' is not correctly loaded. Make sure to read the correct dataset using the alias pd.\\n\"}]}"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0/2 tests passed; 2 failed\n",
       "========\n",
       "__main__.test_pandas_loaded\n",
       "========\n",
       "Traceback (most recent call last):\n",
       "  File \"C:\\Users\\ASUS\\Anaconda3\\lib\\unittest\\case.py\", line 59, in testPartExecutor\n",
       "    yield\n",
       "  File \"C:\\Users\\ASUS\\Anaconda3\\lib\\unittest\\case.py\", line 615, in run\n",
       "    testMethod()\n",
       "  File \"C:\\Users\\ASUS\\Anaconda3\\lib\\site-packages\\nose\\case.py\", line 197, in runTest\n",
       "    self.test(*self.arg)\n",
       "  File \"<string>\", line 4, in test_pandas_loaded\n",
       "AssertionError: Make sure to import pandas library with the alias pd\n",
       "\n",
       "========\n",
       "__main__.test_nobel_loaded\n",
       "========\n",
       "Traceback (most recent call last):\n",
       "  File \"C:\\Users\\ASUS\\Anaconda3\\lib\\unittest\\case.py\", line 59, in testPartExecutor\n",
       "    yield\n",
       "  File \"C:\\Users\\ASUS\\Anaconda3\\lib\\unittest\\case.py\", line 615, in run\n",
       "    testMethod()\n",
       "  File \"C:\\Users\\ASUS\\Anaconda3\\lib\\site-packages\\nose\\case.py\", line 197, in runTest\n",
       "    self.test(*self.arg)\n",
       "  File \"<string>\", line 8, in test_nobel_loaded\n",
       "AssertionError: The dataset 'Nobel' is not correctly loaded. Make sure to read the correct dataset using the alias pd.\n",
       "\n"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%nose # needed at the start of every tests cell\n",
    "\n",
    "def test_pandas_loaded():\n",
    "    assert 'pd' in globals(), \\\n",
    "    \"Make sure to import pandas library with the alias pd\"\n",
    "\n",
    "def test_nobel_loaded():\n",
    "    assert 'pd' in globals(), \\\n",
    "    \"The dataset 'Nobel' is not correctly loaded. Make sure to read the correct dataset using the alias pd.\"\n",
    "    #Since the code below will be error if a student doesn't use the alias pd and the error message is not for our students. \n",
    "    #So I decided to check if pd is in a namespace first. This seems to be inefficient. \n",
    "    #Maybe another solution should be to check both conditions in one function? \n",
    "    correct_nobel = pd.read_csv(\"datasets/nobel.csv\") \n",
    "    assert  correct_nobel.equals(nobel), \\\n",
    "    \"The dataset 'Nobel' is not correctly loaded. Make sure to read the correct dataset.\"\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A potential **correct** solution is as follows. Please process the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load library\n",
    "import pandas as pd\n",
    "\n",
    "# read in the dataset\n",
    "nobel = pd.read_csv('datasets/nobel.csv')\n",
    "#nobel = pd.read_csv('datasets/disney_characters.csv') # use this line to test if the pd exists but a student read a wrong file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please copy and paste the tests you just wrote into the cell below and process the cell. Both tests should pass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": "{\"success\": true, \"summary\": {\"tests\": 2, \"failures\": 0, \"errors\": 0}, \"tests\": [{\"name\": \"__main__.test_pandas_loaded\", \"success\": true, \"message\": \"\"}, {\"name\": \"__main__.test_nobel_loaded\", \"success\": true, \"message\": \"\"}]}"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2/2 tests passed\n"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%nose # needed at the start of every tests cell\n",
    "\n",
    "def test_pandas_loaded():\n",
    "    assert 'pd' in globals(), \\\n",
    "    \"Make sure to import pandas library with the alias pd\"\n",
    "\n",
    "def test_nobel_loaded():\n",
    "    assert 'pd' in globals(), \"The dataset 'Nobel' is not correctly loaded. Make sure to read the correct dataset using the alias pd.\"\n",
    "    correct_nobel = pd.read_csv(\"datasets/nobel.csv\")\n",
    "    assert  correct_nobel.equals(nobel), \\\n",
    "    \"The dataset 'Nobel' is not correctly loaded. Make sure to read the correct dataset.\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
